{"cells":[{"metadata":{},"cell_type":"markdown","source":"Importing the required packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as n\nimport torch.nn.functional as f\nimport torch.optim as optim\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the celebrity dataset folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"# INPUT_DATA_DIR=\"/home/aiteam/TeamData/Vishal_Data/Learning/DataSet\"\nINPUT_DATA_DIR=\"celeba-dataset/img_align_celeba/img_align_celeba/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking whether cuda is available or not "},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.cuda.is_available()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assigning the device as cuda if cuda is available else cpu"},{"metadata":{"trusted":true},"cell_type":"code","source":"cuda = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining some of the hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"LR_D = 0.0002\nLR_G = 0.0002\nBATCH_SIZE = 128\nEPOCHS = 10000\nBETA1 = 0.5\nWEIGHT_INIT_STDDEV = 0.02","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DCGAN paper specifies that the weights be randomly initialized from normal distribution with mean of 0 and standard deviation of 0.02. This function do the same for the weights of the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        n.init.normal_(m.weight.data, 0.0, WEIGHT_INIT_STDDEV)\n    elif classname.find('BatchNorm') != -1:\n        n.init.normal_(m.weight.data, 1.0, WEIGHT_INIT_STDDEV)\n        n.init.constant_(m.bias.data, 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the Generator as given in the DCGAN paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Generator(n.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = n.ConvTranspose2d(100,512,4,1,0,bias=False)\n        self.bn1 = n.BatchNorm2d(512)\n        self.conv2 = n.ConvTranspose2d(512,256,4,2,1,bias=False)\n        self.bn2 = n.BatchNorm2d(256)\n        self.conv3 = n.ConvTranspose2d(256,128,4,2,1,bias=False)\n        self.bn3 = n.BatchNorm2d(128)\n        self.conv4 = n.ConvTranspose2d(128,64,4,2,1,bias=False)\n        self.bn4 = n.BatchNorm2d(64)\n        self.conv5 = n.ConvTranspose2d(64,3,4,2,1,bias=False)\n\n    def forward(self,input):\n        conv = f.relu(self.bn1(self.conv1(input)))\n        conv = f.relu(self.bn2(self.conv2(conv)))\n        conv = f.relu(self.bn3(self.conv3(conv)))\n        conv = f.relu(self.bn4(self.conv4(conv)))\n        out = torch.tanh(self.conv5(conv))\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assigning the generator to cuda and initialising the model weights using above mentioned function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# rand = torch.randn(1,100,1,1)\ngen = Generator().to(cuda).float()\ngen.apply(weights_init)\nsummary(gen,(100,1,1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the discriminator acrhitecture as given in the reference paper"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(n.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = n.Conv2d(3,64,4,2,1,bias=False)\n        self.conv2 = n.Conv2d(64,128,4,2,1,bias=False)\n        self.bn2 = n.BatchNorm2d(128)\n        self.conv3 = n.Conv2d(128,256,4,2,1,bias=False)\n        self.bn3 = n.BatchNorm2d(256)\n        self.conv4 = n.Conv2d(256,512,4,2,1,bias=False)\n        self.bn4 = n.BatchNorm2d(512)\n        self.conv5 = n.Conv2d(512,1,4,1,0,bias=False)\n        self.drop = n.Dropout2d(0.2)\n        \n    def forward(self,input):\n        conv = f.leaky_relu(self.conv1(input))\n        conv = f.leaky_relu(self.bn2(self.conv2(conv)))\n        conv = f.leaky_relu(self.bn3(self.conv3(conv)))\n        conv = f.leaky_relu(self.bn4(self.conv4(conv)))\n        out = torch.sigmoid(self.drop(self.conv5(conv)))\n        \n        return out\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Assigning the discriminator to cuda and initialising the model weights using above mentioned function"},{"metadata":{"trusted":true},"cell_type":"code","source":"disc = Discriminator().to(cuda).float()\ndisc.apply(weights_init)\nsummary(disc,(3,64,64))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the binary cross entropy loss, creating the fixed noise to check the output while training and defining the optimizers for generator and discriminator"},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = n.BCELoss()\n\nfixed_noise = torch.randn(2,100,1,1)\n# fixed_noise = torch.FloatTensor(3, 100,1,1).uniform_(0, 1)\n\ngen_optimizer = optim.Adam(gen.parameters(),lr=LR_G,betas=(BETA1,0.999))\ndisc_optimizer = optim.Adam(disc.parameters(),lr=LR_G,betas=(BETA1,0.999))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Display utility of displaying images using matplotlib"},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_samples(sample_images):\n    figure, axes = plt.subplots(1, sample_images.shape[0], figsize = (6,6))\n    for index, axis in enumerate(axes):\n        axis.axis('off')\n        image_array = sample_images[index]\n        axis.imshow(image_array)\n#         image = Image.fromarray(image_array)\n#     plt.savefig(\"DC/DC_\"+str(epoch)+\".png\", bbox_inches='tight', pad_inches=0)\n    plt.show()\n    plt.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Given the noise and checkpoint, Generating the fake images "},{"metadata":{"trusted":true},"cell_type":"code","source":"def imagePostProcess(noise,modelPath):\n    model = load_checkpoint(modelPath)\n    im_tensor = noise.float()\n    out_tensor = model(im_tensor)\n#     print(out_tensor.shape)\n    out = np.reshape(out_tensor,[out_tensor.shape[0],out_tensor.shape[2],out_tensor.shape[3],out_tensor.shape[1]])\n    out = out.numpy()\n    \n    out = np.clip(out,0,1)\n    \n    return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_checkpoint(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n    \n    model.eval()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loadImages(imageList,path,resize=False):\n    images=[]\n    for image in (imageList):\n        if resize==True:\n            img = cv2.resize(cv2.imread(os.path.join(path,image)),(64,64)) \n        else:\n            img = cv2.imread(os.path.join(path,image))\n        img = img.reshape(img.shape[2],img.shape[0],img.shape[1])\n        images.append(img)\n    return np.array(images)/255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = os.listdir(INPUT_DATA_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_folder = os.path.join(os.getcwd(),\"DCGAN_weights\")\nif not os.path.exists(weight_folder):\n    os.makedirs(weight_folder)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining the losses for generator and discriminator and training both of them"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_count = len(data)//BATCH_SIZE\n# batch_count=200\nfor epoch in range(EPOCHS):\n    Gloss=[]\n    Dloss=[]\n    for batch in tqdm(range(batch_count)):\n        disc.zero_grad()\n        data_list = data[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE]\n        data_batch = loadImages(data_list,INPUT_DATA_DIR,True)\n        \n        real_label = torch.ones(BATCH_SIZE,1,device=cuda,dtype=torch.float)\n#         real_label = torch.FloatTensor(BATCH_SIZE, 1).uniform_(0.9, 1).to(cuda)\n        \n        disc_out = disc(torch.from_numpy(data_batch).to(cuda).float())\n        disc_out = disc_out.reshape((BATCH_SIZE,1))\n#         print(disc_out.shape)\n#         print(real_label.type)\n        Dloss_real = criterion(disc_out,real_label)\n        Dloss_real.backward()\n        \n        noise = torch.randn(BATCH_SIZE, 100, 1, 1, device=cuda)\n        \n#         noise = torch.FloatTensor(BATCH_SIZE, 100,1,1).uniform_(0, 1).to(cuda)\n        fake_image = gen(noise)\n        fake_out = disc(fake_image)\n        fake_out = fake_out.reshape((BATCH_SIZE,1))\n \n        fake_label = torch.zeros(BATCH_SIZE,1,device=cuda,dtype=torch.float)\n#         fake_label = torch.FloatTensor(BATCH_SIZE, 1).uniform_(0, 0.1).to(cuda)\n    \n#     \n        Dloss_fake = criterion(fake_out,fake_label)\n#         Dloss_fake = 1 - fake_out\n        Dloss_fake.sum().backward(retain_graph=True)\n        dloss = Dloss_real+Dloss_fake\n#         print(dloss.mean().item())\n        Dloss.append(dloss.item())\n#         dloss.backward(retain_graph=True)\n  \n        disc_optimizer.step()\n        \n        gen.zero_grad()\n        gloss = criterion(fake_out,real_label)\n        \n        gloss.backward()\n        Gloss.append(gloss.item())\n        n.utils.clip_grad_norm_(gen.parameters(),1e3)\n        \n        gen_optimizer.step()\n        \n        torch.cuda.empty_cache()\n        \n        \n    if(epoch%5==0):\n\n        checkpoint = {'model': Generator(),\n              'input_size': 64,\n              'output_size': 64,\n              'state_dict': gen.state_dict()}\n        torch.save(checkpoint,os.path.join(weight_folder,\"DCGAN\"+str(epoch+1)+\".pth\"))\n\n        out_images = imagePostProcess(fixed_noise,os.path.join(weight_folder,\"DCGAN\"+str(epoch+1)+\".pth\"))\n        show_samples(out_images)\n    print(\"Epoch ::::  \"+str(epoch+1)+\" GenLoss ==>> \"+str(np.mean(Gloss))+\" DiscLoss ==>> \"+str(np.mean(Dloss)))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}